<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>What I learned from ByteDance | Openinx Blog</title>
<meta name=keywords content="Career,Data,AI,ByteDance"><meta name=description content="I recently had the pleasure of joining Databricks, but I often reflect on my profoundly rewarding experience at ByteDance. Before joining ByteDance, I was a software engineer who had written code for a decade. My core responsibility was to tackle system design and code development for complex software while ensuring robust operations in production environments. At ByteDance, however, I led a 16-person technical team (mostly Senior+ engineers) responsible for building the competitiveness of ByteDance’s public cloud EMR open-source engines—a role that was immensely challenging yet transformative for me."><meta name=author content="Zheng Hu"><link rel=canonical href=https://openinx.github.io/posts/2025-05-04-review-bytedance-journey/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://openinx.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://openinx.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://openinx.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://openinx.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://openinx.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://openinx.github.io/posts/2025-05-04-review-bytedance-journey/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-B52L98PJKS"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B52L98PJKS")}</script><meta property="og:url" content="https://openinx.github.io/posts/2025-05-04-review-bytedance-journey/"><meta property="og:site_name" content="Openinx Blog"><meta property="og:title" content="What I learned from ByteDance"><meta property="og:description" content="I recently had the pleasure of joining Databricks, but I often reflect on my profoundly rewarding experience at ByteDance. Before joining ByteDance, I was a software engineer who had written code for a decade. My core responsibility was to tackle system design and code development for complex software while ensuring robust operations in production environments. At ByteDance, however, I led a 16-person technical team (mostly Senior+ engineers) responsible for building the competitiveness of ByteDance’s public cloud EMR open-source engines—a role that was immensely challenging yet transformative for me."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-04T23:16:23-07:00"><meta property="article:modified_time" content="2025-05-04T23:16:23-07:00"><meta property="article:tag" content="Career"><meta property="article:tag" content="Data"><meta property="article:tag" content="AI"><meta property="article:tag" content="ByteDance"><meta property="og:image" content="https://openinx.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://openinx.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="What I learned from ByteDance"><meta name=twitter:description content="I recently had the pleasure of joining Databricks, but I often reflect on my profoundly rewarding experience at ByteDance. Before joining ByteDance, I was a software engineer who had written code for a decade. My core responsibility was to tackle system design and code development for complex software while ensuring robust operations in production environments. At ByteDance, however, I led a 16-person technical team (mostly Senior+ engineers) responsible for building the competitiveness of ByteDance’s public cloud EMR open-source engines—a role that was immensely challenging yet transformative for me."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://openinx.github.io/posts/"},{"@type":"ListItem","position":2,"name":"What I learned from ByteDance","item":"https://openinx.github.io/posts/2025-05-04-review-bytedance-journey/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"What I learned from ByteDance","name":"What I learned from ByteDance","description":"I recently had the pleasure of joining Databricks, but I often reflect on my profoundly rewarding experience at ByteDance. Before joining ByteDance, I was a software engineer who had written code for a decade. My core responsibility was to tackle system design and code development for complex software while ensuring robust operations in production environments. At ByteDance, however, I led a 16-person technical team (mostly Senior+ engineers) responsible for building the competitiveness of ByteDance’s public cloud EMR open-source engines—a role that was immensely challenging yet transformative for me.","keywords":["Career","Data","AI","ByteDance"],"articleBody":"I recently had the pleasure of joining Databricks, but I often reflect on my profoundly rewarding experience at ByteDance. Before joining ByteDance, I was a software engineer who had written code for a decade. My core responsibility was to tackle system design and code development for complex software while ensuring robust operations in production environments. At ByteDance, however, I led a 16-person technical team (mostly Senior+ engineers) responsible for building the competitiveness of ByteDance’s public cloud EMR open-source engines—a role that was immensely challenging yet transformative for me. Through this article, I want to share what I gained from working at ByteDance.\nBackground Due to my contributions to the Apache community, ByteDance’s EMR director contacted me and invited me to join the EMR team to lead the open-source engine direction. In June 2021, ByteDance officially announced its entry into the public cloud market and launched Volcano Engine. Consider this: Alibaba Cloud started in 2009, Tencent Cloud was announced in 2013, and Huawei Cloud began external services in 2016—mainstream players in China’s public cloud market had all undergone roughly a decade of refinement. Given the investment cycles of the cloud computing industry and market dynamics, the industry generally held a pessimistic view of Volcano Engine’s prospects at the time. Of course, times have changed. With ByteDance’s heavy investments in AI, Volcano Engine’s market position is now incomparable to its early days. It must be said that the ByteDance EMR director was an exceptionally charismatic leader. He told me: “In this new team, you can lead the team to build many new projects from scratch and create massive impact for customers, products, and the team.” This resonated deeply with Steve Jobs’ famous question to John Sculley: “Do you want to spend the rest of your life selling sugared water, or do you want a chance to change the world?” The idea of “leading a team to build impactful new projects from scratch” fascinated me, so I chose to join.\nWhen I joined, ByteDance EMR was still in a relatively early stage. The classic EMR product covered components like Hadoop, Hive, Spark, Presto \u0026 Trino, StarRocks \u0026 Doris, HBase, Kafka, and Flink, spanning batch processing, OLAP analytics, and streaming. This vast scope gave our team immense potential. However, as an early-stage product, we abandoned overly ambitious and impractical “grandiose” goals, focusing instead on “how to iteratively launch product commercialization from zero and incrementally shape engine competitiveness through customer scenarios and industry product reviews.” We conducted in-depth research into the core advantages and investment directions of mainstream cloud vendors and startups, including but not limited to:\nStorage-Computation Separation: After 2020, migrating data from traditional HDFS to cloud object storage (e.g., AWS S3, ByteDance TOS, Aliyun OSS) became a consensus among vendors, customers, and the industry. Thus, the team universally prioritized this initiative. Object storage is not a file system. In terms of semantics, S3 lacks file and directory concepts, has slow List performance, and does not support Rename. In terms of performance, QPS and bandwidth throttling of object storage are critical bottlenecks. The question was: How to invest? The industry has “transparent acceleration” solutions like Alluxio, S3FS, and GooseFS, as well as “non-transparent acceleration” solutions like JuiceFS and OSS-HDFS. “Non-transparent acceleration” designs its own metadata, theoretically enabling better semantics and performance, but risks user lock-in by maintaining closed data on S3. “Transparent acceleration” keeps S3 data open and transparent to users, natively compatible with all S3 ecosystems. Matching the semantics and performance of “non-transparent acceleration” wasn’t impossible—just more complex. Ultimately, we chose “keep complexity for ourselves, simplicity for customers” and developed a proprietary transparent acceleration solution: the Proton project [7]. This proved to be an extremely correct decision, rapidly accelerating our product’s revenue growth.\nLakehouse \u0026 Data Lake Direction: Delta [1], open-sourced by Databricks in 2019, popularized the Data Lake concept in the data field. Iceberg and Delta became the hottest projects. We explored sub-directions of Iceberg, such as materialized views, secondary indexes, and page-level caching acceleration. However, considering the maturity of the LakeHouse concept in China and commercialization priorities, these sub-directions were temporarily deprioritized. Still, we maintained continuous investment in open-source Lakehouse solutions to ensure competitiveness.\nIntelligent Data Optimization: Industry players like AWS Redshift [2], Snowflake [3], and Databricks [4] have their own intelligent data optimization solutions. For example, Redshift intelligently detects interactive queries and physical data to automatically select Sort Keys, Distribution Keys, and column compression methods for workload optimization. Unlike these single-engine solutions, EMR is a hybrid product covering batch, streaming, and OLAP. Customers might combine engines in C(20, n) ways, making it difficult to predict and quantify the benefits of single-engine intelligence. We ultimately deprioritized investments in this area short-term.\nSpark Native Direction: Databricks’ 2022 Photon paper [5] was highly influential. In my view, after over a decade of iteration, revolutionary innovations like Photon—which can improve Spark’s performance by multiples for general workloads—are exceedingly rare. After reading the Photon paper, I felt exhilarated, thinking: “This is the direction we need to invest in.” Meanwhile, ByteDance runs tens of millions of Spark cores internally, and internal teams were considering similar investments. The two sides aligned perfectly. Today, Spark Native solutions are widely deployed in ByteDance’s internal and EMR production environments, becoming a core competitive advantage.\nOLAP Direction: In North America, leading products like AWS Athena, Starburst, and Dremio are largely built on Presto/Trino/Drill analytics engines and S3. However, China’s customer market is entirely different. Initially, Baidu’s team forked Impala for secondary development, creating the Apache Doris MPP database. Another company, CelerData, built the StarRocks project on Apache Doris, achieving significant commercial progress. Later, Baidu’s team spun off to establish SelectDB. Both SelectDB and CelerData secured tens of millions in venture funding, building strong technical competitiveness (subsecond query latency, fast row-level updates, native vectorized execution, CBO optimization) and commercial traction in China. Based on market and industry trends, we decided to invest in StarRocks/Doris, launching the Serverless StarRocks service [8] with storage-computation separation. Revenue scale and growth in this area have been exceptional.\nIn the big data era, the above strategies succeeded during the cold-start phase. Leadership clearly aligned customer, sales, product, R\u0026D, and testing workflows to ensure high-priority initiatives received resources and execution. As an R\u0026D team, we closely followed customer scenarios and iterated rapidly. Ultimately, Volcano EMR achieved successful commercialization: execution → customer satisfaction → revenue growth → resource allocation → stronger execution → … Once the product gained momentum, it snowballed. In short, our product revenue charted an impressive growth curve.\nAs the era’s train races forward, the AI age arrived swiftly—GPT-3 in November 2022, GPT-4 in March 2023. Starting in 2023, ByteDance’s Volcano Engine fully embraced AI. Leveraging ByteDance’s intensive investments in AI infrastructure, GPU resources, and talent (¥80 billion in 2024, doubling to ¥160 billion in 2025), Volcano Engine quickly outpaced competitors, capturing 46.4% of China’s token call market share in 2024 [9], with revenue multiplying (2025 projections suggest doubling again [10]). Without doubt, ByteDance’s Volcano Engine successfully seized AI opportunities. Within this trend, I believe EMR also capitalized on the wave—for instance, through investments in Lance [11].\nSetting aside details, I want to emphasize core principles I learned at ByteDance:\nCustomer First\nCustomers are paramount, a principle reiterated in many companies’ leadership tenets. Amazon’s “Customer Obsession” states: “Leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Although leaders pay attention to competitors, they obsess over customers.” ByteDance’s teams took this to extremes. Every member—from sales to engineers—closely tracked customer needs. We even invited customers to co-review products, iterating based on their requirements.\nFrom another angle, customers wield immense influence. Their legitimate demands often secure company-wide resource allocation. Thus, addressing customer needs equates to securing more resources, enabling teams to deliver better results.\nFinally, consistent positive customer feedback creates a self-reinforcing cycle across “customer → sales → product → R\u0026D,” amplifying the snowball effect.\nRadical, Radical, Radical\nByteDance CEO Zhang Yiming once said: “If I could advise my past self from five years ago, it would be: Be more radical.” This ethos is encoded in ByteDance’s DNA. From Toutiao’s rise to Douyin/TikTok’s 2016-2017 launch and subsequent dominance in ads, e-commerce, and local services—all scaling to a hundred-billion-dollar company in years. In AI, ByteDance’s aggressiveness continued: after ChatGPT-3’s 2022 debut, ByteDance invested heavily. Its 2023 Doubao model underperformed, but by 2024, it led China’s token call volume. The 2025 plan to double investments exemplifies extreme radicalism. During DeepSeek’s model releases in late 2024, many ByteDance teams studied papers and models during holidays to absorb traffic. Recognizing Doubao’s lag behind DeepSeek, ByteDance immediately recruited Wu Yonghui to lead AGI efforts. EMR’s team mirrored this radicalism—rapidly closing gaps with competitors and aggressively investing in AI for revenue growth.\nBold Hypotheses, Rigorous Validation\nThis complements “Radical, Radical, Radical.” Radicalism isn’t aimless—it’s aggressively exploring new directions, rigorously evaluating them, then concentrating resources on core bets. ByteDance calls this “Achieving miracles through brute force”—where “brute force” means radicalism across strategy, execution, and commercialization, while “miracles” emerge only in select directions. For example, over the past year+, we aggressively researched subfields including:\nData Pre-training (SparkML, Ray [12], Daft [13]) Vector Databases (Milvus, ElasticSearch) RAG (LLamaIndex, LangChain, Glean [14]) Post-training Fine-tuning (Databricks ML, Amazon SageMaker) Hybrid Search (ElasticSearch, Rockset) GraphRAG [15] Graph Databases (Nebula Graph, Neo4j) LLM Data Processing (data-juicer [16]) Multimodal Data Lakes (DeepLake [17], LanceDB [18], MosaicML Streaming [19]) Data Version Control (LakeFS [20], DVC [21], Git-LFS [22]) Data Annotation (Scale.AI [23]). After rigorous review, we cautiously invested in a few directions. Product revenue and cross-functional feedback confirmed our choices. While cross-domain leaps (e.g., Data → AI) have low success rates, radical investment paired with rational insights makes success possible. This is the power of “Bold Hypotheses, Rigorous Validation.”\nLeverage Synergies\nBefore ByteDance, I underestimated organizational leverage. My manager taught me: “Always borrow strength.” This means identifying shared interests, building partnerships, and creating win-win outcomes. Our team maximized this—collaborating with internal/external teams to rapidly achieve product goals.\nSimplify Complexity to the Extreme\n“Simplify complexity to the extreme” is a principle I internalized through software design. Code often involves tangled if-else logic, loops, and nested method calls. As products evolve, complexity grows exponentially with code volume. The difference between senior and junior engineers lies in the former’s ability to manage complexity via abstraction and trade-offs—abstracting requirements, design, and code while balancing performance, features, and complexity.\nDuring Proton’s development, I applied this mindset. I reviewed every design and code detail, relentlessly reducing complexity. The results were extraordinary: we built Proton, a hundreds-of-thousands-of-line storage middleware, serving massive customer datasets (from TBs to hundreds of PBs) with zero data loss or downtime. One incident stands out: a customer found Impala + ProtonCache + TOS slower than Impala + HDFS. Three team members spent a week troubleshooting. We suspected ProtonCache’s IO optimizations until discovering Impala’s HDFS-specific fd caching. Adding similar caching for ProtonCache resolved the issue. This taught me that extreme simplification and full ownership of engineering details deliver stability beyond expectations.\nConclusion My ByteDance experience was the fastest-growing chapter of my career. I witnessed a product’s journey from 0→1→100—a thrilling “startup” journey. I gained profound insights into industry knowledge, leadership, cross-team collaboration, methodology, and engineering rigor. I’m deeply grateful to my manager for mentoring me and to all colleagues whose collaboration made miracles possible. For everyone, Wish all the best !\nReferences https://www.databricks.com/company/newsroom/press-releases/databricks-open-sources-delta-lake-for-data-lake-reliability https://docs.aws.amazon.com/redshift/latest/dg/t_Creating_tables.html https://www.snowflake.com/en/blog/automatic-query-optimization-no-tuning/ https://docs.databricks.com/aws/en/delta/clustering https://people.eecs.berkeley.edu/~matei/papers/2022/sigmod_photon.pdf https://doris.apache.org/ https://www.volcengine.com/docs/6491/149821 https://www.volcengine.com/docs/6491/1134307 https://finance.sina.com.cn/stock/relnews/hk/2025-04-11/doc-inesuhfw5087507.shtml https://finance.sina.com.cn/jjxw/2024-12-31/doc-ineciptz2736843.shtml https://openinx.github.io/posts/2025-04-11-iceberg-summit-2025-2/ https://github.com/ray-project/ray https://www.getdaft.io/ https://www.glean.com/ https://arxiv.org/abs/2404.16130 https://github.com/modelscope/data-juicer https://github.com/activeloopai/deeplake https://lancedb.github.io/lancedb/basic/ https://github.com/mosaicml/streaming https://scale.com/ https://dvc.org/ https://git-lfs.com/ ","wordCount":"1915","inLanguage":"en","image":"https://openinx.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-05-04T23:16:23-07:00","dateModified":"2025-05-04T23:16:23-07:00","author":{"@type":"Person","name":"Zheng Hu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://openinx.github.io/posts/2025-05-04-review-bytedance-journey/"},"publisher":{"@type":"Organization","name":"Openinx Blog","logo":{"@type":"ImageObject","url":"https://openinx.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://openinx.github.io/ accesskey=h title="openinx (Alt + H)">openinx</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://openinx.github.io/about/ title=About><span>About</span></a></li><li><a href=https://openinx.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://openinx.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://openinx.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://openinx.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">What I learned from ByteDance</h1><div class=post-meta><span title='2025-05-04 23:16:23 -0700 PDT'>May 4, 2025</span>&nbsp;·&nbsp;Zheng Hu</div></header><div class=post-content><p>I recently had the pleasure of joining Databricks, but I often reflect on my profoundly rewarding experience at ByteDance. Before joining ByteDance, I was a software engineer who had written code for a decade. My core responsibility was to tackle system design and code development for complex software while ensuring robust operations in production environments. At ByteDance, however, I led a 16-person technical team (mostly Senior+ engineers) responsible for building the competitiveness of ByteDance’s public cloud EMR open-source engines—a role that was immensely challenging yet transformative for me. Through this article, I want to share what I gained from working at ByteDance.</p><h3 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h3><p>Due to my contributions to the Apache community, ByteDance’s EMR director contacted me and invited me to join the EMR team to lead the open-source engine direction. In June 2021, ByteDance officially announced its entry into the public cloud market and launched Volcano Engine. Consider this: Alibaba Cloud started in 2009, Tencent Cloud was announced in 2013, and Huawei Cloud began external services in 2016—mainstream players in China’s public cloud market had all undergone roughly a decade of refinement. Given the investment cycles of the cloud computing industry and market dynamics, the industry generally held a pessimistic view of Volcano Engine’s prospects at the time. Of course, times have changed. With ByteDance’s heavy investments in AI, Volcano Engine’s market position is now incomparable to its early days. It must be said that the ByteDance EMR director was an exceptionally charismatic leader. He told me: <em>&ldquo;In this new team, you can lead the team to build many new projects from scratch and create massive impact for customers, products, and the team.&rdquo;</em> This resonated deeply with Steve Jobs’ famous question to John Sculley: <em>&ldquo;Do you want to spend the rest of your life selling sugared water, or do you want a chance to change the world?&rdquo;</em> The idea of <em>&ldquo;leading a team to build impactful new projects from scratch&rdquo;</em> fascinated me, so I chose to join.</p><p>When I joined, ByteDance EMR was still in a relatively early stage. The classic EMR product covered components like Hadoop, Hive, Spark, Presto & Trino, StarRocks & Doris, HBase, Kafka, and Flink, spanning batch processing, OLAP analytics, and streaming. This vast scope gave our team immense potential. However, as an early-stage product, we abandoned overly ambitious and impractical &ldquo;grandiose&rdquo; goals, focusing instead on <em>&ldquo;how to iteratively launch product commercialization from zero and incrementally shape engine competitiveness through customer scenarios and industry product reviews.&rdquo;</em> We conducted in-depth research into the core advantages and investment directions of mainstream cloud vendors and startups, including but not limited to:</p><ul><li><p><strong>Storage-Computation Separation</strong>: After 2020, migrating data from traditional HDFS to cloud object storage (e.g., AWS S3, ByteDance TOS, Aliyun OSS) became a consensus among vendors, customers, and the industry. Thus, the team universally prioritized this initiative. Object storage is not a file system. In terms of semantics, S3 lacks file and directory concepts, has slow List performance, and does not support Rename. In terms of performance, QPS and bandwidth throttling of object storage are critical bottlenecks. The question was: How to invest? The industry has &ldquo;transparent acceleration&rdquo; solutions like Alluxio, S3FS, and GooseFS, as well as &ldquo;non-transparent acceleration&rdquo; solutions like JuiceFS and OSS-HDFS. &ldquo;Non-transparent acceleration&rdquo; designs its own metadata, theoretically enabling better semantics and performance, but risks user lock-in by maintaining closed data on S3. &ldquo;Transparent acceleration&rdquo; keeps S3 data open and transparent to users, natively compatible with all S3 ecosystems. Matching the semantics and performance of &ldquo;non-transparent acceleration&rdquo; wasn’t impossible—just more complex. Ultimately, we chose <em>&ldquo;keep complexity for ourselves, simplicity for customers&rdquo;</em> and developed a proprietary transparent acceleration solution: the <strong>Proton project [7]</strong>. This proved to be an extremely correct decision, rapidly accelerating our product’s revenue growth.</p></li><li><p><strong>Lakehouse & Data Lake Direction</strong>: Delta [1], open-sourced by Databricks in 2019, popularized the Data Lake concept in the data field. Iceberg and Delta became the hottest projects. We explored sub-directions of Iceberg, such as materialized views, secondary indexes, and page-level caching acceleration. However, considering the maturity of the LakeHouse concept in China and commercialization priorities, these sub-directions were temporarily deprioritized. Still, we maintained continuous investment in open-source Lakehouse solutions to ensure competitiveness.</p></li><li><p><strong>Intelligent Data Optimization</strong>: Industry players like AWS Redshift [2], Snowflake [3], and Databricks [4] have their own intelligent data optimization solutions. For example, Redshift intelligently detects interactive queries and physical data to automatically select Sort Keys, Distribution Keys, and column compression methods for workload optimization. Unlike these single-engine solutions, EMR is a hybrid product covering batch, streaming, and OLAP. Customers might combine engines in C(20, n) ways, making it difficult to predict and quantify the benefits of single-engine intelligence. We ultimately deprioritized investments in this area short-term.</p></li><li><p><strong>Spark Native Direction</strong>: Databricks’ 2022 Photon paper [5] was highly influential. In my view, after over a decade of iteration, revolutionary innovations like Photon—which can improve Spark’s performance by multiples for general workloads—are exceedingly rare. After reading the Photon paper, I felt exhilarated, thinking: <em>&ldquo;This is the direction we need to invest in.&rdquo;</em> Meanwhile, ByteDance runs tens of millions of Spark cores internally, and internal teams were considering similar investments. The two sides aligned perfectly. Today, Spark Native solutions are widely deployed in ByteDance’s internal and EMR production environments, becoming a core competitive advantage.</p></li><li><p><strong>OLAP Direction</strong>: In North America, leading products like AWS Athena, Starburst, and Dremio are largely built on Presto/Trino/Drill analytics engines and S3. However, China’s customer market is entirely different. Initially, Baidu’s team forked Impala for secondary development, creating the Apache Doris MPP database. Another company, CelerData, built the StarRocks project on Apache Doris, achieving significant commercial progress. Later, Baidu’s team spun off to establish SelectDB. Both SelectDB and CelerData secured tens of millions in venture funding, building strong technical competitiveness (subsecond query latency, fast row-level updates, native vectorized execution, CBO optimization) and commercial traction in China. Based on market and industry trends, we decided to invest in StarRocks/Doris, launching the Serverless StarRocks service [8] with storage-computation separation. Revenue scale and growth in this area have been exceptional.</p></li></ul><p>In the big data era, the above strategies succeeded during the cold-start phase. Leadership clearly aligned customer, sales, product, R&amp;D, and testing workflows to ensure high-priority initiatives received resources and execution. As an R&amp;D team, we closely followed customer scenarios and iterated rapidly. Ultimately, Volcano EMR achieved successful commercialization: <em>execution → customer satisfaction → revenue growth → resource allocation → stronger execution → &mldr;</em> Once the product gained momentum, it snowballed. In short, our product revenue charted an impressive growth curve.</p><p>As the era’s train races forward, the AI age arrived swiftly—GPT-3 in November 2022, GPT-4 in March 2023. Starting in 2023, ByteDance’s Volcano Engine fully embraced AI. Leveraging ByteDance’s intensive investments in AI infrastructure, GPU resources, and talent (¥80 billion in 2024, doubling to ¥160 billion in 2025), Volcano Engine quickly outpaced competitors, capturing 46.4% of China’s token call market share in 2024 [9], with revenue multiplying (2025 projections suggest doubling again [10]). Without doubt, ByteDance’s Volcano Engine successfully seized AI opportunities. Within this trend, I believe EMR also capitalized on the wave—for instance, through investments in Lance [11].</p><p>Setting aside details, I want to emphasize core principles I learned at ByteDance:</p><p><strong>Customer First</strong><br>Customers are paramount, a principle reiterated in many companies’ leadership tenets. Amazon’s <em>&ldquo;Customer Obsession&rdquo;</em> states: <em>&ldquo;Leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Although leaders pay attention to competitors, they obsess over customers.&rdquo;</em> ByteDance’s teams took this to extremes. Every member—from sales to engineers—closely tracked customer needs. We even invited customers to co-review products, iterating based on their requirements.</p><p>From another angle, customers wield immense influence. Their legitimate demands often secure company-wide resource allocation. Thus, addressing customer needs equates to securing more resources, enabling teams to deliver better results.</p><p>Finally, consistent positive customer feedback creates a self-reinforcing cycle across <em>&ldquo;customer → sales → product → R&amp;D,&rdquo;</em> amplifying the snowball effect.</p><p><strong>Radical, Radical, Radical</strong><br>ByteDance CEO Zhang Yiming once said: <em>&ldquo;If I could advise my past self from five years ago, it would be: Be more radical.&rdquo;</em> This ethos is encoded in ByteDance’s DNA. From Toutiao’s rise to Douyin/TikTok’s 2016-2017 launch and subsequent dominance in ads, e-commerce, and local services—all scaling to a hundred-billion-dollar company in years. In AI, ByteDance’s aggressiveness continued: after ChatGPT-3’s 2022 debut, ByteDance invested heavily. Its 2023 Doubao model underperformed, but by 2024, it led China’s token call volume. The 2025 plan to double investments exemplifies extreme radicalism. During DeepSeek’s model releases in late 2024, many ByteDance teams studied papers and models during holidays to absorb traffic. Recognizing Doubao’s lag behind DeepSeek, ByteDance immediately recruited Wu Yonghui to lead AGI efforts. EMR’s team mirrored this radicalism—rapidly closing gaps with competitors and aggressively investing in AI for revenue growth.</p><p><strong>Bold Hypotheses, Rigorous Validation</strong><br>This complements <em>&ldquo;Radical, Radical, Radical.&rdquo;</em> Radicalism isn’t aimless—it’s aggressively exploring new directions, rigorously evaluating them, then concentrating resources on core bets. ByteDance calls this <em>&ldquo;Achieving miracles through brute force&rdquo;</em>—where <em>&ldquo;brute force&rdquo;</em> means radicalism across strategy, execution, and commercialization, while <em>&ldquo;miracles&rdquo;</em> emerge only in select directions. For example, over the past year+, we aggressively researched subfields including:</p><ul><li>Data Pre-training (SparkML, Ray [12], Daft [13])</li><li>Vector Databases (Milvus, ElasticSearch)</li><li>RAG (LLamaIndex, LangChain, Glean [14])</li><li>Post-training Fine-tuning (Databricks ML, Amazon SageMaker)</li><li>Hybrid Search (ElasticSearch, Rockset)</li><li>GraphRAG [15]</li><li>Graph Databases (Nebula Graph, Neo4j)</li><li>LLM Data Processing (data-juicer [16])</li><li>Multimodal Data Lakes (DeepLake [17], LanceDB [18], MosaicML Streaming [19])</li><li>Data Version Control (LakeFS [20], DVC [21], Git-LFS [22])</li><li>Data Annotation (Scale.AI [23]).</li></ul><p>After rigorous review, we cautiously invested in a few directions. Product revenue and cross-functional feedback confirmed our choices. While cross-domain leaps (e.g., Data → AI) have low success rates, radical investment paired with rational insights makes success possible. This is the power of <em>&ldquo;Bold Hypotheses, Rigorous Validation.&rdquo;</em></p><p><strong>Leverage Synergies</strong><br>Before ByteDance, I underestimated organizational leverage. My manager taught me: <em>&ldquo;Always borrow strength.&rdquo;</em> This means identifying shared interests, building partnerships, and creating win-win outcomes. Our team maximized this—collaborating with internal/external teams to rapidly achieve product goals.</p><p><strong>Simplify Complexity to the Extreme</strong><br><em>&ldquo;Simplify complexity to the extreme&rdquo;</em> is a principle I internalized through software design. Code often involves tangled if-else logic, loops, and nested method calls. As products evolve, complexity grows exponentially with code volume. The difference between senior and junior engineers lies in the former’s ability to manage complexity via abstraction and trade-offs—abstracting requirements, design, and code while balancing performance, features, and complexity.</p><p>During Proton’s development, I applied this mindset. I reviewed every design and code detail, relentlessly reducing complexity. The results were extraordinary: we built Proton, a hundreds-of-thousands-of-line storage middleware, serving massive customer datasets (from TBs to hundreds of PBs) with zero data loss or downtime. One incident stands out: a customer found Impala + ProtonCache + TOS slower than Impala + HDFS. Three team members spent a week troubleshooting. We suspected ProtonCache’s IO optimizations until discovering Impala’s HDFS-specific fd caching. Adding similar caching for ProtonCache resolved the issue. This taught me that extreme simplification and full ownership of engineering details deliver stability beyond expectations.</p><h3 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h3><p>My ByteDance experience was the fastest-growing chapter of my career. I witnessed a product’s journey from 0→1→100—a thrilling &ldquo;startup&rdquo; journey. I gained profound insights into industry knowledge, leadership, cross-team collaboration, methodology, and engineering rigor. I’m deeply grateful to my manager for mentoring me and to all colleagues whose collaboration made miracles possible. For everyone, Wish all the best !</p><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><ol><li><a href=https://www.databricks.com/company/newsroom/press-releases/databricks-open-sources-delta-lake-for-data-lake-reliability>https://www.databricks.com/company/newsroom/press-releases/databricks-open-sources-delta-lake-for-data-lake-reliability</a></li><li><a href=https://docs.aws.amazon.com/redshift/latest/dg/t_Creating_tables.html>https://docs.aws.amazon.com/redshift/latest/dg/t_Creating_tables.html</a></li><li><a href=https://www.snowflake.com/en/blog/automatic-query-optimization-no-tuning/>https://www.snowflake.com/en/blog/automatic-query-optimization-no-tuning/</a></li><li><a href=https://docs.databricks.com/aws/en/delta/clustering>https://docs.databricks.com/aws/en/delta/clustering</a></li><li><a href=https://people.eecs.berkeley.edu/~matei/papers/2022/sigmod_photon.pdf>https://people.eecs.berkeley.edu/~matei/papers/2022/sigmod_photon.pdf</a></li><li><a href=https://doris.apache.org/>https://doris.apache.org/</a></li><li><a href=https://www.volcengine.com/docs/6491/149821>https://www.volcengine.com/docs/6491/149821</a></li><li><a href=https://www.volcengine.com/docs/6491/1134307>https://www.volcengine.com/docs/6491/1134307</a></li><li><a href=https://finance.sina.com.cn/stock/relnews/hk/2025-04-11/doc-inesuhfw5087507.shtml>https://finance.sina.com.cn/stock/relnews/hk/2025-04-11/doc-inesuhfw5087507.shtml</a></li><li><a href=https://finance.sina.com.cn/jjxw/2024-12-31/doc-ineciptz2736843.shtml>https://finance.sina.com.cn/jjxw/2024-12-31/doc-ineciptz2736843.shtml</a></li><li><a href=https://openinx.github.io/posts/2025-04-11-iceberg-summit-2025-2/>https://openinx.github.io/posts/2025-04-11-iceberg-summit-2025-2/</a></li><li><a href=https://github.com/ray-project/ray>https://github.com/ray-project/ray</a></li><li><a href=https://www.getdaft.io/>https://www.getdaft.io/</a></li><li><a href=https://www.glean.com/>https://www.glean.com/</a></li><li><a href=https://arxiv.org/abs/2404.16130>https://arxiv.org/abs/2404.16130</a></li><li><a href=https://github.com/modelscope/data-juicer>https://github.com/modelscope/data-juicer</a></li><li><a href=https://github.com/activeloopai/deeplake>https://github.com/activeloopai/deeplake</a></li><li><a href=https://lancedb.github.io/lancedb/basic/>https://lancedb.github.io/lancedb/basic/</a></li><li><a href=https://github.com/mosaicml/streaming>https://github.com/mosaicml/streaming</a></li><li><a href=https://scale.com/>https://scale.com/</a></li><li><a href=https://dvc.org/>https://dvc.org/</a></li><li><a href=https://git-lfs.com/>https://git-lfs.com/</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://openinx.github.io/tags/career/>Career</a></li><li><a href=https://openinx.github.io/tags/data/>Data</a></li><li><a href=https://openinx.github.io/tags/ai/>AI</a></li><li><a href=https://openinx.github.io/tags/bytedance/>ByteDance</a></li></ul><nav class=paginav><a class=prev href=https://openinx.github.io/posts/2025-05-11-new-us-saas/><span class=title>« Prev</span><br><span>Thoughts of SaaS services</span>
</a><a class=next href=https://openinx.github.io/posts/2025-04-11-iceberg-summit-2025-2/><span class=title>Next »</span><br><span>Iceberg Summit 2025 - Part 2</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://openinx.github.io/>Openinx Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>